# Test Cases: Intelligent Search & Chatbot

This document contains test cases for the Intelligent Search & Chatbot user stories (US3.1 - US3.5).

## TC-IS1: Document Content Indexing (US3.1)

### Description
Verify that the system automatically processes and indexes the content of uploaded documents.

### Pre-conditions
- User is logged in as a Project Manager (TC-C1)
- User has navigated to a specific project's documents section (TC-DH1)

### Test Steps
1. Upload a document with text content (e.g., PDF, DOCX, TXT) (TC-DH2)
2. Wait for the background indexing process to complete (may take a few moments)
3. Click on the chatbot button in the interface
4. Ask a question specifically about the content in the newly uploaded document

### Expected Results
- Document is successfully uploaded
- Background indexing process completes without errors
- Chatbot can answer questions based on the content of the newly uploaded document
- Chatbot response includes reference to the newly uploaded document

### UI Elements
- Upload button and dialog (as described in TC-DH2)
- Chatbot button (typically a chat or message icon)
- Chatbot interface with:
  - Message history area
  - Input field for questions
  - Send button
  - References/sources section in responses

## TC-IS2: Failed Document Indexing (US3.1)

### Description
Verify that the system handles failures in document indexing gracefully.

### Pre-conditions
- User is logged in as a Project Manager (TC-C1)
- User has navigated to a specific project's documents section (TC-DH1)

### Test Steps
1. Upload a document with a supported format but corrupted content or with no extractable text
2. Wait for the background indexing process to attempt processing
3. Check system logs or admin notifications (if available to the user)
4. Try asking the chatbot a question about the document content

### Expected Results
- Document upload itself succeeds
- System handles the indexing failure gracefully
- If the chatbot is asked about the document content, it responds appropriately (e.g., indicating it doesn't have information about that document)
- System continues to function normally despite the indexing failure

### UI Elements
- Upload button and dialog (as described in TC-DH2)
- Chatbot interface
- Possibly an admin notification area for indexing failures (if implemented)

## TC-IS3: Access Chatbot Interface (US3.2)

### Description
Verify that users can easily access the chatbot interface.

### Pre-conditions
- User is logged in (TC-C1)
- User has access to at least one project

### Test Steps
1. Look for a chatbot button/icon in the interface (typically in the navigation bar or corner of the screen)
2. Click on the chatbot button/icon

### Expected Results
- Chatbot button/icon is clearly visible in the interface
- Clicking the button opens the chatbot interface
- Chatbot interface includes a message history area and text input field
- Chatbot may display a welcome message or suggested queries

### UI Elements
- Chatbot button/icon (typically in the corner of the screen or navigation area)
- Chatbot interface panel/modal with:
  - Header with title and close button
  - Message history area
  - Input field for questions
  - Send button
  - Possibly suggested queries or help information

## TC-IS4: Ask Question Within Project (US3.3)

### Description
Verify that users can ask questions about documents within a specific project.

### Pre-conditions
- User is logged in (TC-C1)
- User has navigated to a specific project with indexed documents
- User has opened the chatbot interface (TC-IS3)

### Test Steps
1. Verify the chatbot interface indicates it's in project-specific mode
2. Type a specific question related to content known to be in the project's documents (e.g., "What is the budget for this project?")
3. Click the send button or press Enter
4. Observe the chatbot's response

### Expected Results
- Question appears in the message history
- Loading/typing indicator is displayed while processing
- Chatbot processes the question and generates a response within a reasonable time
- Response is relevant to the question and based on information in the project's documents
- Response includes references to source documents

### UI Elements
- Chatbot interface with:
  - Project context indicator (showing current project name)
  - Message history area showing user questions and chatbot responses
  - Input field for questions
  - Send button
  - Loading/typing indicator
  - References/sources section in responses

## TC-IS5: Ask Question with No Relevant Content (US3.3)

### Description
Verify that the chatbot handles questions with no relevant content in the project documents.

### Pre-conditions
- User is logged in (TC-C1)
- User has navigated to a specific project
- User has opened the chatbot interface (TC-IS3)

### Test Steps
1. Type a question about a topic that is definitely not covered in any project document
2. Click the send button or press Enter
3. Observe the chatbot's response

### Expected Results
- Question appears in the message history
- Loading/typing indicator is displayed while processing
- Chatbot responds with a message indicating it cannot find relevant information
- Response is polite and may suggest alternatives (e.g., reformulating the question, checking other projects)

### UI Elements
- Chatbot interface with:
  - Message history area showing the question and "no information found" response
  - Possibly suggested alternative queries
  - Input field for follow-up questions

## TC-IS6: Get Answers with Source References (US3.4)

### Description
Verify that chatbot answers include references to source documents.

### Pre-conditions
- User is logged in (TC-C1)
- User has navigated to a specific project with indexed documents
- User has opened the chatbot interface (TC-IS3)

### Test Steps
1. Type a specific question related to content known to be in the project's documents
2. Click the send button or press Enter
3. Observe the chatbot's response and source references section

### Expected Results
- Chatbot provides a relevant answer to the question
- Below the answer, there is a "Sources" or "References" section
- Section lists 1-3 documents most relevant to the answer
- Each source is displayed as a clickable link with document name/icon
- Sources are from the current project context

### UI Elements
- Chatbot interface with:
  - Message history area showing the question and response
  - Sources/references section below the response
  - Clickable document links in the sources section
  - Possibly document icons indicating file types

## TC-IS7: Verify Source References Accuracy (US3.4)

### Description
Verify that the source references provided by the chatbot are accurate.

### Pre-conditions
- User is logged in (TC-C1)
- User has navigated to a specific project with indexed documents
- User has received an answer with source references from the chatbot (TC-IS6)

### Test Steps
1. Click on a source reference link in the chatbot response
2. Review the opened document
3. Verify that the information in the chatbot's answer is actually present in the referenced document

### Expected Results
- Source link opens the correct document in the document viewer
- The referenced document contains information relevant to the question
- The information in the chatbot's answer can be found in the document
- Document viewer allows user to return to the chatbot conversation

### UI Elements
- Clickable source references in chatbot responses
- Document viewer (as described in TC-DH5)
- Navigation to return from document viewer to chatbot conversation

## TC-IS8: Ask Question Across All Projects (US3.5)

### Description
Verify that a Director can ask questions that query documents across all projects.

### Pre-conditions
- User is logged in as a Director (TC-C1)
- Multiple projects exist with indexed documents
- User has opened the chatbot interface (TC-IS3)

### Test Steps
1. Look for and click on a "Global Mode" toggle or similar option in the chatbot interface
2. Verify the chatbot interface indicates it will search across all accessible projects
3. Type a question that would require information from multiple projects (e.g., "Which projects are using the 'Agile' methodology?")
4. Click the send button or press Enter
5. Observe the chatbot's response and source references

### Expected Results
- Chatbot interface indicates it's in global mode (searching across all projects)
- Question appears in the message history
- Loading/typing indicator is displayed while processing
- Chatbot processes the question and generates a response
- Response synthesizes information from relevant documents across multiple projects
- Source references indicate which project each referenced document belongs to

### UI Elements
- Chatbot interface with:
  - Global/Project mode toggle or selector
  - Visual indication of current mode (global vs. project-specific)
  - Message history area
  - Input field for questions
  - Send button
  - Sources/references section showing project context for each source

## TC-IS9: Chatbot Conversation History (General)

### Description
Verify that the chatbot maintains conversation history within a session.

### Pre-conditions
- User is logged in (TC-C1)
- User has opened the chatbot interface (TC-IS3)

### Test Steps
1. Ask an initial question and receive a response
2. Ask a follow-up question related to the first question
3. Ask a third question referencing both previous questions or responses

### Expected Results
- All questions and responses are displayed in the conversation history in chronological order
- Chatbot maintains context between questions
- Follow-up questions are understood in the context of the conversation
- User can scroll through the conversation history if it becomes lengthy

### UI Elements
- Chatbot interface with:
  - Scrollable message history area showing all questions and responses
  - Clear visual distinction between user messages and chatbot responses
  - Timestamps for messages (if implemented)
  - Scroll controls or auto-scrolling behavior

## TC-IS10: Chatbot Session Persistence (General)

### Description
Verify whether chatbot conversations persist between user sessions.

### Pre-conditions
- User is logged in (TC-C1)
- User has had a conversation with the chatbot (TC-IS9)

### Test Steps
1. Log out of the system (TC-C2)
2. Log back in (TC-C1)
3. Open the chatbot interface (TC-IS3)
4. Check if the previous conversation history is available

### Expected Results
- System behavior is consistent with design requirements:
  - If designed to persist conversations: Previous conversation history is available
  - If designed for session-only conversations: A new, empty conversation starts

### UI Elements
- Chatbot interface with message history area
- Possibly conversation history selector if multiple conversations are saved
- Possibly a "New Conversation" button if persistence is implemented

## TC-IS11: Chatbot Response Time (Performance)

### Description
Verify that the chatbot responds within an acceptable time frame.

### Pre-conditions
- User is logged in (TC-C1)
- User has opened the chatbot interface (TC-IS3)

### Test Steps
1. Ask a simple question about project content
2. Measure the time from submission to receiving a response
3. Ask a complex question that would require synthesizing information from multiple documents
4. Measure the time from submission to receiving a response

### Expected Results
- Simple question: Response received within 2-3 seconds
- Complex question: Response received within 5-10 seconds
- Visual indicator (e.g., "typing" animation) shows that the chatbot is processing during wait times
- System remains responsive during chatbot processing

### UI Elements
- Chatbot interface with:
  - Send button (becomes disabled during processing if implemented that way)
  - Loading/typing indicator while waiting for response
  - Timestamp or response time indicator (if implemented) 